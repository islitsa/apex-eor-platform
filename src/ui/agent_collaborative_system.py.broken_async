"""
Enhanced AutoGen Agent Collaboration System

This version maximizes the benefits of agent collaboration with:
- Critique rounds
- Implementation feedback
- Iterative refinement
- Visible reasoning
"""

import streamlit as st
import os
import json
from typing import Dict, List, Any
from pathlib import Path
import sys

# Add project root
project_root = Path(__file__).resolve().parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Load .env file for API keys
from dotenv import load_dotenv
load_dotenv()

# AutoGen imports - v0.10+ uses autogen_agentchat
try:
    from autogen_agentchat.agents import AssistantAgent
    from autogen_agentchat.base import TaskResult
    from autogen_agentchat.teams import RoundRobinGroupChat
    from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination
    from autogen_core.models import ChatCompletionClient
    from autogen_ext.models.anthropic import AnthropicChatCompletionClient
    import autogen_agentchat
    AUTOGEN_AVAILABLE = True
except ImportError as e:
    AUTOGEN_AVAILABLE = False
    AUTOGEN_ERROR = str(e)
    # Define dummy types when AutoGen is not available
    TaskResult = Any
    AssistantAgent = Any
    RoundRobinGroupChat = Any
    TextMentionTermination = Any
    MaxMessageTermination = Any
    AnthropicChatCompletionClient = Any

from shared_state import PipelineState


class CollaborativeUIGenerator:
    """
    Advanced agent system with real collaboration, critique, and refinement
    """

    def __init__(self, chat_container, terminal_container):
        self.chat_container = chat_container
        self.terminal_container = terminal_container
        self.api_key = os.getenv("ANTHROPIC_API_KEY")

        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not set")

        # Create specialized agents with critique capabilities
        self._create_collaborative_agents()

    def _create_model_client(self):
        """Create Claude model client for AutoGen v0.10+"""
        return AnthropicChatCompletionClient(
            model="claude-3-5-sonnet-20241022",
            api_key=self.api_key
        )

    def _create_collaborative_agents(self):
        """Create agents that actually collaborate and critique"""

        model_client = self._create_model_client()

        # UX Designer - The Visionary
        self.ux_designer = AssistantAgent(
            name="UX_Designer",
            model_client=model_client,
            system_message="""You are a Senior UX Designer with 10 years of experience.

Your collaboration style:
- PROPOSE designs with clear rationale
- LISTEN to technical constraints from the developer
- ADAPT designs based on implementation feedback
- CRITIQUE implementation for UX issues
- ITERATE until optimal solution reached

When designing:
1. Start with user needs and workflows
2. Propose specific components and layouts
3. Be ready to adapt based on technical constraints
4. Always explain your design decisions
5. Point out potential UX issues in implementations

Format your responses clearly:
- State your design decisions
- List components needed
- Explain interaction patterns
- Respond to developer feedback constructively"""
        )

        # Gradio Developer - The Realist
        self.gradio_developer = AssistantAgent(
            name="Gradio_Developer",
            model_client=model_client,
            system_message="""You are a Gradio Framework Expert with deep knowledge of its capabilities and limitations.

Your collaboration style:
- EVALUATE design feasibility
- PROVIDE FEEDBACK on technical constraints
- SUGGEST alternatives when designs aren't possible
- IMPLEMENT designs with best practices
- ASK for clarification when needed

When implementing:
1. First, review the design for feasibility
2. Point out any Gradio limitations
3. Suggest alternative approaches if needed
4. Implement the agreed-upon design
5. Optimize for performance and user experience

Format your responses clearly:
- State technical constraints upfront
- Propose alternatives when needed
- Show code in ```python blocks
- Explain implementation decisions

Known Gradio constraints to watch for:
- No nested modals
- Tab performance issues with >5 tabs
- Plot update minimum interval: 1 second
- No native lazy loading (must implement)
- Limited styling options (CSS limitations)"""
        )

        # UX Critic - Reviews implementations
        self.ux_critic = AssistantAgent(
            name="UX_Critic",
            model_client=model_client,
            system_message="""You are a UX Quality Reviewer who ensures implementations meet UX standards.

Your role:
- REVIEW implementations for UX issues
- IDENTIFY missing UX elements
- SUGGEST improvements
- VALIDATE user workflow coverage

Focus on:
- Accessibility
- Error handling
- Loading states
- User feedback
- Visual hierarchy
- Responsive design"""
        )

        # Code Reviewer - Ensures code quality
        self.code_reviewer = AssistantAgent(
            name="Code_Reviewer",
            model_client=model_client,
            system_message="""You are a Code Quality Expert who ensures implementations are production-ready.

Your role:
- CHECK code for errors
- VERIFY completeness
- ENSURE best practices
- VALIDATE functionality

Focus on:
- Code completeness (no placeholders)
- Error handling
- Performance optimization
- Security considerations
- Documentation"""
        )

    async def generate_with_collaboration(self, requirements: Dict, context: Dict) -> str:
        """
        Generate UI through multi-round agent collaboration

        Process:
        1. UX Designer proposes initial design
        2. Gradio Developer reviews and provides feedback
        3. They iterate until agreement
        4. Developer implements
        5. Critics review
        6. Final refinements
        """

        # Craft initial message to start collaboration
        initial_message = f"""Let's collaborate to create an exceptional UI.

REQUIREMENTS:
{json.dumps(requirements, indent=2)}

CONTEXT:
- Data Sources: {list(context.get('data_sources', {}).keys())}
- Total Records: {context.get('summary', {}).get('human_readable_records', 'Unknown')}

COLLABORATION PROCESS:
1. UX_Designer: Propose your initial design
2. Gradio_Developer: Review for feasibility and provide feedback
3. Both: Iterate until we have an agreed design
4. Gradio_Developer: Implement the design
5. UX_Critic: Review implementation for UX issues
6. Code_Reviewer: Ensure code quality
7. Gradio_Developer: Address any concerns and provide final code

When code is final and complete, end your message with: COLLABORATION_COMPLETE

Start by having the UX_Designer propose a design."""

        # Create group chat with round-robin speaker selection
        termination = TextMentionTermination("COLLABORATION_COMPLETE") | MaxMessageTermination(20)

        team = RoundRobinGroupChat(
            participants=[
                self.ux_designer,
                self.gradio_developer,
                self.ux_critic,
                self.code_reviewer
            ],
            termination_condition=termination
        )

        # Stream output to Streamlit
        message_count = 0

        # Run the collaboration
        async for message in team.run_stream(task=initial_message):
            message_count += 1

            # Display in chat container
            if self.chat_container and hasattr(message, 'source'):
                with self.chat_container:
                    agent_name = message.source
                    content = message.content if hasattr(message, 'content') else str(message)

                    # Style based on agent
                    if agent_name == "UX_Designer":
                        st.markdown("### UX Designer")
                        st.markdown(content)
                    elif agent_name == "Gradio_Developer":
                        st.markdown("### Gradio Developer")
                        st.markdown(content)
                    elif agent_name == "UX_Critic":
                        st.markdown("### UX Critic")
                        st.markdown(content)
                    elif agent_name == "Code_Reviewer":
                        st.markdown("### Code Reviewer")
                        st.markdown(content)

                    st.divider()

            # Also show in terminal
            if self.terminal_container:
                with self.terminal_container:
                    st.text(f"[{message_count}] {message.source if hasattr(message, 'source') else 'System'}")

        # Get final result
        result = await team.run(task=initial_message)

        # Extract final code
        return self._extract_final_code(result)

    def _extract_final_code(self, result: TaskResult) -> str:
        """Extract the final, refined code from the conversation"""

        import re

        # Get all messages
        messages = result.messages if hasattr(result, 'messages') else []

        # Look for code blocks in reverse order (latest = most refined)
        for message in reversed(messages):
            content = str(message)

            # Find Python code blocks
            code_blocks = re.findall(r"```python\n(.*?)\n```", content, re.DOTALL)

            if code_blocks:
                # Return the last (most complete) code block
                return code_blocks[-1]

        return "# No code generated"


class EnhancedAgentRunner:
    """Runner with collaborative agent system"""

    def __init__(self):
        st.set_page_config(
            page_title="Collaborative Agent UI Generator",
            page_icon="AI",
            layout="wide"
        )

        # Session state
        if 'status' not in st.session_state:
            st.session_state.status = 'initializing'
        if 'generated_code' not in st.session_state:
            st.session_state.generated_code = None
        if 'context' not in st.session_state:
            st.session_state.context = None
        if 'messages' not in st.session_state:
            st.session_state.messages = []

    def run(self):
        st.title("AI Collaborative Agent UI Generator")
        st.markdown("**Watch agents critique, refine, and perfect your UI through collaboration!**")

        # Check AutoGen availability
        if not AUTOGEN_AVAILABLE:
            st.error(f"""
            AutoGen not properly installed in your venv!

            Error: {AUTOGEN_ERROR}

            Please install in your venv:
            ```bash
            pip install pyautogen autogen-ext[anthropic]
            ```
            """)
            st.stop()

        # Load context and AUTO-START
        if not st.session_state.context:
            with st.spinner("Loading context and generating prompt..."):
                context = PipelineState.load_context(check_freshness=False)
                if context:
                    st.session_state.context = context

                    # Generate prompt from context
                    datasets = list(context.get('data_sources', {}).keys())
                    total_records = context.get('summary', {}).get('human_readable_records', 'Unknown')

                    # Determine UI type based on data
                    if 'production' in str(datasets).lower():
                        ui_type = "production monitoring dashboard"
                    elif 'permits' in str(datasets).lower():
                        ui_type = "permit tracking interface"
                    elif 'completions' in str(datasets).lower():
                        ui_type = "well completion analyzer"
                    else:
                        ui_type = "data exploration dashboard"

                    st.session_state.prompt = f"""Create a {ui_type} with the following requirements:

1. Display data from {len(datasets)} sources: {', '.join(datasets)}
2. Handle {total_records} total records efficiently
3. Include interactive filtering and drill-down capabilities
4. Use Material Design 3 patterns for modern UX
5. Implement real-time data refresh capabilities
6. Add export functionality for reports

Focus on usability and performance for petroleum engineering workflows."""

                    st.success(f"Context loaded: {len(datasets)} data sources, {total_records} records")

                    # AUTO-START GENERATION
                    st.session_state.status = 'generating'
                    st.rerun()
                else:
                    st.error("No context found. Run: python scripts/pipeline/run_ingestion.py --all")
                    st.stop()

        # Status
        if st.session_state.status == 'initializing':
            st.info("Ready to start collaborative generation")
        elif st.session_state.status == 'generating':
            st.warning("Agents are collaborating...")
        elif st.session_state.status == 'complete':
            st.success("Collaboration complete!")

        # Controls (no Start button - auto-starts!)
        col1, col2 = st.columns(2)

        with col1:
            if st.session_state.generated_code:
                if st.button("Save Code", type="primary"):
                    path = project_root / "generated_collaborative_ui.py"
                    path.write_text(st.session_state.generated_code, encoding='utf-8')
                    st.success(f"Saved to {path}")

        with col2:
            if st.button("Regenerate"):
                st.session_state.status = 'initializing'
                st.session_state.generated_code = None
                st.session_state.messages = []
                st.session_state.context = None  # Force reload
                st.rerun()

        st.markdown("---")

        # Show generated prompt
        if st.session_state.get('prompt'):
            with st.expander("ðŸ“‹ Generated Prompt (from context)", expanded=False):
                st.info(st.session_state.prompt)

        # Display areas
        col_chat, col_terminal = st.columns([2, 1])

        with col_chat:
            st.subheader("Agent Collaboration")
            chat_container = st.container(height=600)

        with col_terminal:
            st.subheader("Terminal")
            terminal_container = st.container(height=600)

        # Generate if requested (auto-started after context load)
        if st.session_state.status == 'generating':
            import asyncio

            generator = CollaborativeUIGenerator(chat_container, terminal_container)

            # Use the prompt generated from context
            requirements = {
                'screen_type': 'dashboard',
                'intent': st.session_state.prompt,  # Use generated prompt!
                'data_sources': st.session_state.context.get('data_sources', {})
            }

            # Run async generation
            try:
                code = asyncio.run(generator.generate_with_collaboration(
                    requirements,
                    st.session_state.context
                ))

                st.session_state.generated_code = code
                st.session_state.status = 'complete'
                st.rerun()
            except Exception as e:
                st.error(f"Generation failed: {e}")
                st.session_state.status = 'initializing'

        # Show code if complete
        if st.session_state.generated_code:
            with st.expander("Generated Code", expanded=True):
                st.code(st.session_state.generated_code, language='python')


if __name__ == "__main__":
    if not os.getenv("ANTHROPIC_API_KEY"):
        st.error("Set ANTHROPIC_API_KEY environment variable")
        st.stop()

    runner = EnhancedAgentRunner()
    runner.run()
